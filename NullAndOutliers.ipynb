{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import sys\n",
    "import math\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "#from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "import pyspark.ml.evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ev.Evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc=SparkContext()\n",
    "spark=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def remove_dup(park2):\n",
    "#     park2=park2.dropDuplicates()\n",
    "#     return park2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printf(i,m,n):\n",
    "    print(i,\":\",m,n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kcluster(dataset):\n",
    "    kmeans = KMeans().setK(2).setSeed(1)\n",
    "    model = kmeans.fit(dataset)\n",
    "    predictions = model.transform(dataset)\n",
    "    centers = model.clusterCenters()\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_null(dataset):\n",
    "    with_null=dataset.na.fill('Null')\n",
    "    n=math.floor(len(park2.columns)/2)\n",
    "    dataset=dataset.na.drop(how='any',thresh=n)\n",
    "    #cluster=kcluster(dataset)\n",
    "    return dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove DUPLICATE Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_dup(dataset):\n",
    "    dataset=dataset.dropDuplicates()\n",
    "    m=dataset.count()\n",
    "    #l1,n=remove_null(dataset)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_space(dataset,column_list=None):\n",
    "    column_name=dataset.columns\n",
    "    for i in column_name:\n",
    "        dataset=dataset.trim(i)\n",
    "    return dataset\n",
    "    #dataset=dataset.trim()\n",
    "    #return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing files one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 rmmq-46n5.tsv\n",
      "Before cleaning: 39\n",
      "After cleaning: 39\n",
      "\n",
      "File 2 z4kf-gt4n.tsv\n",
      "Before cleaning: 157\n",
      "After cleaning: 157\n",
      "\n",
      "File 3 5uac-w243.tsv\n",
      "Before cleaning: 361740\n",
      "After cleaning: 361740\n",
      "\n",
      "File 4 3miu-myq2.tsv\n",
      "Before cleaning: 435\n",
      "After cleaning: 435\n",
      "\n",
      "File 5 siju-6isf.tsv\n",
      "Before cleaning: 3136\n",
      "After cleaning: 3136\n",
      "\n",
      "File 6 9akp-irxz.tsv\n",
      "Before cleaning: 347\n",
      "After cleaning: 343\n",
      "\n",
      "File 7 smdw-73pj.tsv\n",
      "Before cleaning: 2462\n",
      "After cleaning: 2457\n",
      "\n",
      "File 8 kku6-nxdu.tsv\n",
      "Before cleaning: 236\n",
      "After cleaning: 236\n",
      "\n",
      "File 9 yu9n-iqyk.tsv\n",
      "Before cleaning: 28465\n",
      "After cleaning: 28465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'uncom/*.tsv'\n",
    "files = glob.glob(path)\n",
    "#print(files)\n",
    "i=1\n",
    "for name in files:\n",
    "    if(i>9):\n",
    "        break\n",
    "    print(\"File \"+str(i),name.split(\"/\")[1])\n",
    "    park = spark.read.format(\"csv\").options(header=\"true\",inferschema=\"true\",delimiter=\"\\t\").load(name)\n",
    "    #park2=trim_space(park)\n",
    "    #trim_columnname=input(\"Enter the column_name\")\n",
    "    #print(park2)\n",
    "    #park.printSchema()\n",
    "    #park.show()\n",
    "    m=park.count()\n",
    "    #centers=kcluster(park)\n",
    "    n=remove_dup(park)\n",
    "    #n=remove_null(park)\n",
    "    #printf(i,m,n)\n",
    "    #print(i,\":\",m,j,n)\n",
    "    print(\"Before cleaning:\",m)\n",
    "    print(\"After cleaning:\",n)\n",
    "    print()\n",
    "    i=i+1\n",
    "#     for center in centers:\n",
    "#         print(center)\n",
    "    #print(math.floor(len(park.columns)/2))\n",
    "    #break\n",
    "    #lines = sc.textFile(sys.argv[1], 1)\n",
    "    #lines.collect()\n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
